<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="content-type" content="text/html; charset=UTF-8">
      <title>个人主页-张恒</title>
      <link rel="icon" href="img/index.jpg">
      <link rel="stylesheet" href="files/style.css">
   </head>
   <body>
      <div id="navigation">
         <div id="profile">
            <a href="img/heng5.jpg"><img src="img/heng5.jpg"></a>
         </div>
         <div id="contact">
            <h1>张 恒</h1>
            <h2 id="title" class="italic">PhD student</h2>
            <p>heng.zhang -AT- inria.fr</p>
            <p>Paris, France</p>
            <p class="link">
               <a href="https://github.com/zhanghengdev/"><img id="github" src="img/github.png" class="external"></a>
               <a href="https://scholar.google.com/citations?user=MbusOqcAAAAJ&hl=en"><img id="scholar" src="img/scholar.png" class="external"></a>
               <a href="https://www.linkedin.com/in/heng-zhang-628177112/"><img id="linkedin" src="img/linkedin.png" class="external"></a>
               <a href="https://www.youtube.com/channel/UCfpG_buvXcF4YRn4AvrTEcQ?view_as=subscriber"><img id="youtube" src="img/youtube.png" class="external"></a>
               <a href="files/CV_cn.pdf"><img id="cv" src="img/cv.png" class="external"></a>
               <a href="index.html"><img id="en-cn" src="img/en.png" class="external"></a>
            </p>
            <br/>
            <img src="img/ezgif-5-118bbd5bda.gif" width="180">
         </div>
      </div>
      <div id="content">
         <div id="intro">
            <h2 id="first">个人信息</h2>
            法国国家信息与自动化研究所（<a href="https://zh.wikipedia.org/wiki/%E6%B3%95%E5%9B%BD%E5%9B%BD%E5%AE%B6%E4%BF%A1%E6%81%AF%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%8C%96%E7%A0%94%E7%A9%B6%E6%89%80">INRIA</a>）在读博士生。在<a href="http://people.irisa.fr/Elisa.Fromont/">Elisa FROMONT</a>教授和<a href="http://people.irisa.fr/Sebastien.Lefevre/">Sébastien LEFEVRE</a>教授的指导下开展计算机视觉相关的科研工作。同时在<a href="https://www.atermes.fr/en/index">ATERMES</a>公司担任深度学习算法工程师。目前的研究方向包括: 目标检测，多传感器融合，主动学习和知识蒸馏。
            <p style="text-align:right;">
               <a href="https://www.irisa.fr/en"><img src="img/irisa.png" height="50"/></a>
               <a href="https://www.inria.fr/en"><img src="img/inria.png" height="50"/></a>
               <a href="https://international.univ-rennes1.fr/"><img src="img/univ-rennes1.png" height="50"/></a>
               <a href="https://www.atermes.fr/en/index"><img src="img/atermes.png" height="50"/></a>
            </p>
         </div>
         <div id="experience">
            <h2>工作经历</h2>
            <ul>
               <li>
                  <p><span class="strong">深度学习算法工程师</span></p>
                  <p>ATERMES | 法国，巴黎 | Dec. 2018 - present </p>
                  <div class="additional-text">
                     <p>&#9646 参与SIAMM项目的完整开发（MultiModal Automatic Identification System）。</p>
                     <p>&#9646 利用主动学习减少所需的数据标注数量。</p>
                     <p>&#9646 训练用于远距离（通常大于1.5km）的物体检测（包括汽车、行人等）的深度学习模型。</p>
                     <p>&#9646 自适应地融合来自多个传感器的信息（例如，可见光和热成像）以提高检测精度。</p>
                     <p>&#9646 针对CNN模型的推理加速，以实现在嵌入式设备上（Nvidia Jetson系列）的实时深度学习应用。</p>
                  </div>
               </li>
               <li>
                  <p><span class="strong">深度学习研究员</span></p>
                  <p>Hubert Curien 实验室 | 法国，圣埃蒂安 | Sep. 2017 - Oct. 2018</p>
                  <div class="additional-text">
                     <p>&#9646 应用多种目标检测方法（Fater-RCNN、SSD、YOLO、RetinaNet）于视频监控中的人脸/人体检测。</p>
                     <p>&#9646 为视频监控应用提出了基于视频流的高效目标检测方法。</p>
                  </div>
               </li>
            </ul>
         </div>
         <div id="education">
            <h2>教育背景</h2>
            <ul>
               <li>
                  <p><span class="strong">在读博士生（深度学习，计算机视觉方向）</span></p>
                  <p>雷恩第一大学 | 法国，雷恩 | Dec. 2018 - present </p>
                  <div class="additional-text">
                     <p>&#9646 博士课题: Multispectral object detection</p>
                     <p>&#9646 面向工业界的博士项目（与ATERMES公司合作）</p>
                  </div>
               </li>
               <li>
                  <p><span class="strong">工程师学位（硕士学位）</span></p>
                  <p>圣太田大学圣太田电信学校 | 法国，圣太田 | Sep. 2015 - Oct. 2018</p>
                  <div class="additional-text">
                     <p>&#9646 主修计算机科学与图像识别</p>
                     <p>&#9646 在Hubert Curien实验室担任一年的深度学习研究员</p>
                  </div>
               </li>
               <li>
                  <p><span class="strong">本科学位</span></p>
                  <p>西安电子科技大学 | 中国，西安 | Sep. 2012 - Jun. 2016</p>
                  <div class="additional-text">
                     <p>&#9646 电子信息工程专业</p>
                  </div>
               </li>
            </ul>
         </div>
         <div id="publication">
            <h2>主要论文(以实际产品开发为目的)</h2>
            <ul>
               <li>
                  <p><span class="strong">"Localize to Classify and Classify to Localize: Mutual Guidance in Object Detection", in <i>ACCV 2020</i></span></p>
                  <p><b>Heng Zhang</b>, Elisa FROMONT, Sébastien LEFEVRE, Bruno AVIGNON</p>
                  <div class="additional-text">
                     <p>&#9646 <i>Keywords: Object Detection, Label Assignment, Anchor Matching</i></p>
                  </div>
                  <small>
                     利用目标检测中的定位任务与分类任务间的相互指导，实现自适应的标签分配和两任务间的自动对齐。
                     <br/>
                     可应用于anchor-based或anchor-free检测器，带来免费性能提升。
                     <br/>
                     512x512分辨率下，MutualGuide采用ResNet18 backbone在COCO数据集的mAP达到42%。
                     <br/>
                     <a href="https://openaccess.thecvf.com/content/ACCV2020/papers/Zhang_Localize_to_Classify_and_Classify_to_Localize_Mutual_Guidance_in_ACCV_2020_paper.pdf">[PDF]</a>
                     <a href="https://github.com/zhanghengdev/MutualGuide">[Code]</a>
                     <a href="https://youtu.be/8gnpOJVDtS0">[Presentation]</a></a>
                     <a href="https://youtu.be/5CYOSIFLakM">[Demo1]</a>
                     <a href="https://youtu.be/LEW_w8UQzRU">[Demo2]</a>
                     <a href="https://github.com/zhanghengdev/MutualGuide"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/zhanghengdev/MutualGuide?style=social"/></a>
                     <br/>
                     <a href="https://zhuanlan.zhihu.com/p/260886323">[知乎解读] 左脚踩右脚，目标检测的精度就能上天？一个新的目标检测锚框匹配方法</a></a>
                  </small>
                  </p>
                  <br/>
                  <p><span class="strong">"PDF-Distil: Including Prediction Disagreements in Feature-based Knowledge Distillation for Object Detection", in <i>BMVC 2021</i></span></p>
                  <p><b>Heng Zhang</b>, Elisa FROMONT, Sébastien LEFEVRE, Bruno AVIGNON</p>
                  <div class="additional-text">
                     <p>&#9646 <i>Keywords: Object Detection, Knwoledge Distillation, Model Compression</i></p>
                  </div>
                  <small>
                     利用Teacher-Student模型预测的不一致性动态的指导检测模型的知识蒸馏。优于SOTA的蒸馏方法。
                     <br/>
                     512x512分辨率下，PDF-Distil采用ResNet18 backbone在COCO数据集的mAP达到42.9%。
                     <br/>
                     <a href="https://www.bmvc2021.com/">[To appear]</a>
                     <a href="https://github.com/zhanghengdev/MutualGuide">[Code]</a>
                     <a href="https://github.com/zhanghengdev/MutualGuide"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/zhanghengdev/MutualGuide?style=social"/></a>
                     <br/>
                     <a href="https://zhuanlan.zhihu.com/p/422358346">[知乎解读] 挑战YOLOX! 新一代紧凑型目标检测器</a></a>
                  </small>
                  </p>
                  <br/>
                  <p><span class="strong">"Guided Attentive Feature Fusion for Multispectral Pedestrian Detection", in <i>WACV 2021</i></span></p>
                  <p><b>Heng Zhang</b>, Elisa FROMONT, Sébastien LEFEVRE, Bruno AVIGNON</p>
                  <div class="additional-text">
                     <p>&#9646 <i>Keywords: Multispectral Object Detection, Attentive Fusion, Multi-sensor Fusion</i></p>
                  </div>
                  <small>
                     利用有监督的注意力机制，实现多传感器特征的主动自适应融合。
                     <br/>
                     结果显著优于基于无注意力机制或传统注意力机制的融合方法（提升约2%）。
                     <br/>
                     <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Zhang_Guided_Attentive_Feature_Fusion_for_Multispectral_Pedestrian_Detection_WACV_2021_paper.pdf">[PDF]</a>
                     <a href="https://github.com/zhanghengdev/GAFF">[Results]</a>
                     <a href="https://youtu.be/PoQ9guJL8eU">[Presentation]</a>
                     <a href="https://youtu.be/skseGjveeQQ">[Demo]</a>
                     <a href="https://github.com/zhanghengdev/GAFF"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/zhanghengdev/GAFF?style=social"/></a>
                  </small>
                  </p>
                  <br/>
               </li>
            </ul>
            <br/>
            <h2>其他论文</h2>
                  <p><span class="strong">"Low-cost Multispectral Scene Analysis with Modality Distillation", in <i>WACV 2022</i></span></p>
                  <p><b>Heng Zhang</b>, Elisa FROMONT, Sébastien LEFEVRE, Bruno AVIGNON</p>
                  <div class="additional-text">
                     <p>&#9646 <i>Keywords: Multispectral Scene Analysis, Thermal Sensor, Knwoledge Distillation</i></p>
                  </div>
                  <small>
                     利用多传感器融合技术，将摄像头分辨率也纳入到知识蒸馏框架中，降低系统成本的同时减少性能损失。
                     <br/>
                     在KAIST数据集上，与使用所有像素的baseline相比，本方法利用1/16的热成像像素性能仅下降0.26%。
                     <br/>
                     本方法也可用于利用多传感器增强单一传感器的感知性能。
                     <br/>
                     <a href="https://openaccess.thecvf.com/content/WACV2022/html/Zhang_Low-Cost_Multispectral_Scene_Analysis_With_Modality_Distillation_WACV_2022_paper.html">[PDF]</a>
                     <a href="https://video.vast.uccs.edu/WACV22/WACV/313-wacv-poster.pdf">[Poster]</a>
                  </small>
                  </p>
                  <br/>
                  <p><span class="strong">"Deep Active Learning from Multispectral Data Through Cross-Modality Prediction Inconsistency", in <i>ICIP 2021</i></span></p>
                  <p><b>Heng Zhang</b>, Elisa FROMONT, Sébastien LEFEVRE, Bruno AVIGNON</p>
                  <div class="additional-text">
                     <p>&#9646 <i>Keywords: Multispectral Scene Analysis, Active Learning</i></p>
                  </div>
                  <small>
                     利用多传感器间的冗余性实现主动学习，以降低目标检测或语义分割任务所需的数据标注数量。
                     <br/>
                     在KAIST数据集上，与使用所有数据的baseline相比，本方法利用10%的数据标注性能仅下降0.5%。
                     <br/>
                     <a href="https://ieeexplore.ieee.org/document/9506322">[PDF]</a>
                     <a href="https://youtu.be/ZuNIyG51Hms">[Presentation]</a></a>
                  </small>
                  </p>
                  <br/>
                  <p><span class="strong">"Multispectral Fusion for object detection with Cyclic Fuse-and-Refine blocks", in <i>ICIP 2020</i></span></p>
                  <p><b>Heng Zhang</b>, Elisa FROMONT, Sébastien LEFEVRE, Bruno AVIGNON</p>
                  <div class="additional-text">
                     <p>&#9646 <i>Keywords: Multispectral Object Detection, Cyclic Fusion, Multi-sensor Fusion</i></p>
                  </div>
                  <small>
                     利用网络级联结构逐渐消除来自不同传感器之间的特征不一致性，使信息融合更为准确。
                     <br/>
                     <a href="https://ieeexplore.ieee.org/document/9191080">[PDF]</a>
                     <a href="https://github.com/zhanghengdev/CFR">[Results]</a>
                     <a href="https://youtu.be/aIDq0E-_5pc">[Presentation]</a></a> 
                     <a href="https://youtu.be/YBwkmcCwAL8">[Demo]</a>
                     <a href="https://github.com/zhanghengdev/CFR"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/zhanghengdev/CFR?style=social"/></a>
                  </small>
                  </p>
                  <br/>
                  <p><span class="strong">"Improving video object detection by Seq-Bbox Matching", in <i>VISAPP 2018</i></span></p>
                  <p>Hatem Belhassen, <b>Heng Zhang</b>, Virginie Fresse, El-Bay Bourennane</p>
                  <div class="additional-text">
                     <p>&#9646 <i>Keywords: Video Object Detection, Bounding Box Association</i></p>
                  </div>
                  <small>
                     通过建立视频流中帧与帧间目标检测结果的关联，实现目标检测与物体跟踪的高效融合。
                     <br/>
                     与基于图片的目标检测相比，绝对精度提高了6.9%；在ImageNet VID数据集上，mAP达到81.1%。
                     <br/>
                     <a href="https://www.scitepress.org/Papers/2019/72600/72600.pdf">[PDF]</a>
                     <a href="https://youtu.be/hLsTfJ8t3b0">[Demo]</a>
                     <a href="https://github.com/zhanghengdev/awesome-video-object-detection">[List]</a>
                     <a href="https://github.com/zhanghengdev/awesome-video-object-detection"><img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/zhanghengdev/awesome-video-object-detection?style=social"/></a>
                  </small>
                  </p>
               </li>
            </ul>
         </div>
      </div>
   </body>
</html>
